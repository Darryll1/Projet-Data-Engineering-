{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1062167f-20f2-4b76-8b5f-afff459a380a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mount ADLS Gen2\n",
    "# Required each time the cluster is restarted which should be only on the first notebook as they run in order\n",
    "\n",
    "tiers = [\"bronze\", \"silver\", \"gold\"]\n",
    "adls_paths = {tier: f\"abfss://{tier}@stockagedataengineering.dfs.core.windows.net/\" for tier in tiers}\n",
    "\n",
    "# Accessing paths\n",
    "bronze_adls = adls_paths[\"bronze\"]\n",
    "silver_adls = adls_paths[\"silver\"]\n",
    "gold_adls = adls_paths[\"gold\"] \n",
    "\n",
    "dbutils.fs.ls(bronze_adls)\n",
    "dbutils.fs.ls(silver_adls)\n",
    "dbutils.fs.ls(gold_adls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0586dadb-ce25-4ef7-8f7d-e17c5f0c1a5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération du fichier CSV: BridgeEncounterDoctor.csv\nWrote 3338352 bytes.\nFichier BridgeEncounterDoctor.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/BridgeEncounterDoctor.csv\nRécupération du fichier CSV: DimDate.csv\nWrote 1908623 bytes.\nFichier DimDate.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/DimDate.csv\nRécupération du fichier CSV: DimDisease.csv\nWrote 16380 bytes.\nFichier DimDisease.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/DimDisease.csv\nRécupération du fichier CSV: DimDoctor.csv\nWrote 5975 bytes.\nFichier DimDoctor.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/DimDoctor.csv\nRécupération du fichier CSV: DimPatient.csv\nWrote 10140587 bytes.\nFichier DimPatient.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/DimPatient.csv\nRécupération du fichier CSV: DimRoom.csv\nWrote 170 bytes.\nFichier DimRoom.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/DimRoom.csv\nRécupération du fichier CSV: DimTreatment.csv\nWrote 132559 bytes.\nFichier DimTreatment.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/DimTreatment.csv\nRécupération du fichier CSV: FactCost.csv\nWrote 68405141 bytes.\nFichier FactCost.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/FactCost.csv\nRécupération du fichier CSV: FactEncounter.csv\nWrote 17127962 bytes.\nFichier FactEncounter.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/FactEncounter.csv\nRécupération du fichier CSV: FactTreatment.csv\nWrote 29948047 bytes.\nFichier FactTreatment.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/FactTreatment.csv\nRécupération du fichier CSV: FactTreatmentCost.csv\nWrote 83764 bytes.\nFichier FactTreatmentCost.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/FactTreatmentCost.csv\nRécupération du fichier CSV: FactVitals.csv\nWrote 15163674 bytes.\nFichier FactVitals.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/FactVitals.csv\nRécupération du fichier CSV: Patient_Allergy.csv\nWrote 5958987 bytes.\nFichier Patient_Allergy.csv sauvegardé dans Azure Blob Storage à abfss://bronze@stockagedataengineering.dfs.core.windows.net/Patient_Allergy.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Configuration GitLab\n",
    "GITLAB_API_URL = \"https://gitlab.com/api/v4\"\n",
    "PROJECT_ID = \"69289862\"  # l'ID du projet GitLab\n",
    "ACCESS_TOKEN = \"glpat-Xr-VaueKhxp9Z3dPhmHr\" # token d'accès personnel GitLab\n",
    "\n",
    "# Configuration Azure\n",
    "AZURE_CONTAINER_PATH = \"abfss://bronze@stockagedataengineering.dfs.core.windows.net/\" # Chemin vers le conteneur Azure via DBFS\n",
    "\n",
    "# Fonction pour récupérer la liste des fichiers dans un dépôt GitLab\n",
    "def get_gitlab_files(project_id, access_token):\n",
    "    url = f\"{GITLAB_API_URL}/projects/{project_id}/repository/tree\"\n",
    "    headers = {\"Private-Token\": access_token}\n",
    "    params = {\n",
    "        \"ref\": \"main\",  `\n",
    "        \"recursive\": \"true\"  # Pour récupérer tous les fichiers du projet\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Erreur lors de la récupération des fichiers depuis GitLab: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# télécharger un fichier spécifique depuis GitLab\n",
    "def download_file_from_gitlab(file_path, project_id, access_token):\n",
    "    url = f\"{GITLAB_API_URL}/projects/{project_id}/repository/files/{file_path}/raw\"\n",
    "    headers = {\"Private-Token\": access_token}\n",
    "    params = {\"ref\": \"main\"}  # Branche spécifique\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')  # Convertir les bytes en str\n",
    "    else:\n",
    "        print(f\"Erreur lors du téléchargement du fichier {file_path}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "#  sauvegarder le fichier dans Azure via DBFS\n",
    "def save_file_to_azure(file_name, file_content):\n",
    "    # Stocker le fichier dans le conteneur Azure Blob via DBFS\n",
    "    file_path = os.path.join(AZURE_CONTAINER_PATH, file_name)\n",
    "    dbutils.fs.put(file_path, file_content, overwrite=True)  # Sauvegarder avec dbutils\n",
    "    print(f\"Fichier {file_name} sauvegardé dans Azure Blob Storage à {file_path}\")\n",
    "\n",
    "# Main: Récupérer les fichiers CSV depuis GitLab et les stocker dans Azure\n",
    "def main():\n",
    "    files = get_gitlab_files(PROJECT_ID, ACCESS_TOKEN)\n",
    "    \n",
    "    for file in files:\n",
    "        if file['name'].endswith('.csv'):  # Filtrer pour ne récupérer que les fichiers CSV\n",
    "            print(f\"Récupération du fichier CSV: {file['path']}\")\n",
    "            file_content = download_file_from_gitlab(file['path'], PROJECT_ID, ACCESS_TOKEN)\n",
    "            if file_content:\n",
    "                save_file_to_azure(file['name'], file_content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
